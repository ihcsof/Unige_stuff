What is a difference between large-scale data frameworks (e.g Hadoop) and large-scale DBMS? * frameworks don't provide a logical level * framework focus on data representation and querying * frameworks are tailored to transactional processing * 1
Connect RDBMS (1) and LSDBMS (2) featues: application database, semi-structured schema, flat data, joins are an issue and normalization is no more a reference, declarative lang (SQL) * 2, 1, 1, 2, 1 * 2, 2, 1, 2, 1 * 2, 2, 1, 1, 1 * 2
In ?? DB we start from the ?? to model our data, and all the (any) app that will need that data will come later (with different views) * application, domain knowledge * application, relational schema * integration, domain knowledge * 3
An ?? is tailored to account for the design of a niche of apps, with data exchange between apps based on specific format (e.g JSON) and with the chance of putting ACL and integrity checks in the ?? * application DB, app code * application DB, DB code * integration DB, app code * 1
?? are inefficient for large volumes of data (if data are partitioned in 2 nodes, it'll be made 2x2=4 times), so in app DB we use query-based design * products * joins * CRUD operations * 2
?? is a term used to describe the problem that arises when two systems or components that are supposed to work together have different data models or structures that make communication difficult * Impedence mismatch * Inconsistencies * both * 1
Graph based systems are tailored to app where complexity of data is the most important point, while Aggregate oriented systems are designed to deal with common large scale issues * TRUE * FALSE, the opposite * completely FALSE * 1
?? architectures are often P2P, designed for transactional (read/write intensive) scenarios, with hash-based or range-based partitioning for efficient resource usage, leader-less replication, eventual consistency, high and tunable availability, high fault tolerance (often with no master, P2P ring), usually no ACID transactions, and following the AP or CP theorem in the CAP theorem. * Graph based * Aggregate-oriented * None * 2
The notion of aggregate (a data unit with a complex structure)...: * impact the logical level * impact the physical level * both * 3
A ?? exists only if a system that uses that level also exists, and it is a set of constructs that helps us in representing entities and associations corresponding to a general/reference domain * conceptual * logical * None * 2
An aggregate is the unit of interaction with the data store, so: * you have to partition them * you can partition them * you can't partition them * 3
In Application DB there's no such thing as ??, because the logical schema was built with respect to the needs of the few apps that will use it * External (Views) Level * Logical Level * SQL Middleware * 1
?? define how data is logically and physically grouped, impacting search efficiency, concurrency control, and consistency, with NoSQL databases typically supporting atomic manipulation of a single aggregate at a time to avoid inconsistent reads during multi-aggregate updates * Logical views * Aggregate properties * Graph views * 2
These aggregate-orieted logical data models are in what order? Key value, Document-oriented, Column family * increasing data size * increasing data complexity * decreasing data complexity * 2
In aggregate-orieted logical data models, at the physical level, the key is the ??: different aggregates associated with the same key are stored in the same node * partitioning value * JSON required fields * the (non necessarily unique) key of an entity * 1
Without considering a specific aggr.-oriented system: starting from a conceptual schema and a ?? we want to translate them in a meta-logical schema (using JSON ??) * workload, schemas * workload, tables * logical, tables * 1
Aggregate-oriented logical design principles include minimizing ?? by reducing collections, reducing redundancy with complex attributes like arrays or objects, and prioritizing selections over ?? attributes for efficiency * joins, complex * projections, simple * joins, simple * 3
The methodology involves taking an ?? and ?? as input, formally modeling each query, annotating the ER schema with ?? information, and then generating the aggregate-oriented logical schema based on the annotations, which serves as the final output * ER schema, workload, query * query, ER schema, workload * both are ok * 1
The aggregate key is often used as ??* foreign key * partitioning key * parititioning rule * 2
in partitioning with ?? you have that H(K) = i? * chord é cassandra * i betweeen [0, 2^n] *   * 1 i betweeen [0, 2^n-1] * 2
Each node is associated with an ID, which is used for hashing (details on the hashing mechanism are omitted). Aggregates, whose keys are hashed to a value k, are assigned to the first node whose ID is either equal to or immediately follows k in the identifier space (the successor node of k). If S and S' are two adjacent nodes in the ring (in a clockwise direction), all keys in the range ?? are mapped to node S. * (h(S), h(S')] * [h(S), h(S')) * [h(S), h(S')] * 1
In chord, apart from the logN choice, what are the others? * Each node records its successor on the ring * Full duplication of the hash directory at each node * both * 3
In the Chord Ring, how is item x stored on a node? * Corresponding to a random identifier * Matching its specific hash value * Determined by the node's predecessor * 2
What's pros/cons of having chord nodes knowing only the next? * in case of addition only the previous has to be updated * O(N) * first is pro, second is con * 3
How does Chord achieve accelerated lookup in its routing mechanism? * By implementing random node connections * Through the creation of exponential shortcuts (logN lookup) * By establishing direct links to all successor nodes * 2
In Chord's greedy routing, what approach is taken at each step of the lookup process? * Following the closest, but before, finger to the destination * Prioritizing communication with all successor nodes * Randomly selecting a successor at each step * 1
What ensure these CHORD steps: When a node p wants to join, it uses a contact node p' to: initialize p's routing table by locating p's friends, update existing nodes' routing tables via a background "stabilization" protocol that maintains Chord’s finger tables and successor pointers, and transfer items k from its successor where h(k) ≤ h(p) * scalability * replication * fault-tolerance * 1
What ensure this CHORD consistent hashing step: assign keys to m successor nodes * scalability * replication * fault-tolerance * 2
What BASE stands for? * Basically Available, Soft State, Eventual Consistency * Biased Acid Sium Enterprise * Basically Available, Soon or Later, Eventual Consistency * 1
In a ?? data model, each data instance is stored as an opaque pair without a defined structure, allowing high flexibility in data content, with aggregate visibility limited to the application level (logically groupable by collections) * key-value * document-oriented * graph-based * 1
In key-value data models, keys uniquely identify data for retrieval and partitioning, enabling direct access to entire aggregates but not to specific fields, with relationships navigated through sequential lookups, often within a ??-specific namespace * key * collection * aggregate * 2
In a document-oriented data model, each data instance is a (key, value) pair where the key identifies the document, and the value is a structured, accessible aggregate of nested <name, nested-document> pairs, allowing visibility and access at * application level, as key-value ones * both logical and application levels * physical and application level * 2
In ?-oriented data models, ?s are self-describing, hierarchical structures (often in XML, JSON, or BSON) with flexible schemas, allowing dynamic addition of new attributes without predefined schema requirements * key-value * graph * document * 3
In document-oriented data models, collections are logical groupings of documents (key-value pairs) with flexible structures, allowing varied fields across documents, though documents within a collection generally share similar purposes * true * false * true but in MongoDB optional JSON schema validation can enforce data consistency * 3
In ??, an instance hosts multiple databases, each with collections (like tables) where documents are stored (via db.collection.insertOne(document)) with a unique system-generated _id identifier * MongoDB * Cassandra * Redis * 1
Other difference(s) among key-value and document-based? * In doc-based partition key and identifier can be different * In doc-based aggregates can be directly retrieved by specifying values for attributes in the key OR for nested attributes; because the structure of the aggregate is exposed * both * 3
In MongoDB, while unique _id identifiers allow document referencing ??, partition keys play a role in data storage organization * in the context of retrieval * without affecting retrieval * with the chance of affecting retrieval * 2
Interaction with ?? abstracts query language through basic operations for document retrieval and manipulation (like get, put, set, and remove), allowing for queries on nested documents, additional search constraints, partial retrieval through projection, and requiring collection names in each operation when collections are used * Redis * Cassandra * MongoDB * 3
?? supports the aggregation framework and the ?? construct for performing joins, requiring explicit instructions for the system on what to match, but this involves two separate data accesses at potentially different nodes, making it less efficient than queries on embedded relationships * MongoDB, $lookup * Cassandra, $lookup * Cassandra, $join * 1
? is a document-based database with support for aggregation, transactional and analytical scenarios, hash and range-based sharding, primary and secondary indexes, master-slave and replica set replication, strong and eventual (at replicas) consistency, availability through read/write mediation, fault tolerance via replica sets, multi-document ACID transactions and aligns with the ? model of the CAP theorem * MongoDB, AP * MongoDB, CP * Cassandra, AP * 2
Remember that the following practical topics aren't here: 3 steps of creating aggregates from ER and workload + mongoDB queries + Cassandra basic syntax * OK * SIUM * SIUM * 1
db.videos.find({},{title:1}) is a? * projection only with title * projection only with title and id * projection with title and selection of everything * 2
db.collection.find( <query>, <projection> ) return a ?? to handle the result set (imposing limits, sorting, ecc) * cursor * callback * pointer * 1
match " db.W.aggregate([{$lookup: {from: Y, K: <field from the input docs>, Z: <field from the docs of the 'from' collection>, as: X}}]) " with " SELECT all, X FROM W WHERE X IN ( SELECT all FROM Y WHERE Z = <W.K> " * W = <collection to join>, Y = collection, K = localField, Z = <foreignField>, X = <output array field> * W = <collection to join>, Y = collection, K = <foreignField>, Z = <output array field>, X = localField * W = collection, Y = <collection to join>, K = localField, Z = <foreignField>, X = <output array field> * 3
db.orders.aggregate( {$?? : {_id: type, totalquantity: { $sum: quantity} } } ) * having * group * match * 2
MapReduce in ?? performs complex aggregation on key-value pairs using a map function, reduce function, and output collection, with support for automatic parallel processing across partitions (??) if the input is partitioned, and can partition the output collection using the _id field as the partition key if specified * MongoDB, shards * Cassandra, splits * MongoDB, splits * 1
All ?? operations in MongoDB are atomic on the level of a single ?? * write, document * read, aggregate * write, aggregate * 1
MongoDB automatically creates an index on the ? field and enables users to define additional indexes, including single-field, compound, unique, hash, and text indexes, to improve query performance and enforce data constraints; ? indexes take field order into account, while indexing array fields generates entries for each array element. MongoDB also provides a specialized text index to support text ? across documents * _id, compound, search * _id, hash, find * key, hash, search * 1
Ranged sharding is most efficient when the shard key is: * Large Cardinality & Low Frequency * Non-Monotonically Changing * both are true * 3
In ?? replica sets, nodes elect a primary (master) for handling all read and write operations, while secondary nodes asynchronously replicate the primary’s data and handle only ?? requests; if the primary fails, the secondaries vote to elect a new primary, ensuring fault tolerance and continuity despite potential node failures * RDF, write * MongoDB, read * Cassandra, read * 2
In MongoDB, ? transactions at the ? level are supported from version 4.0, requiring all operations to use the primary read preference and route to the same member; data changes remain invisible outside the transaction until it commits * atomic, multi-document * atomic, logical * flat, multi-document * 1
What happens if in Mongo I write db.adminCommand({shardCollection: "db.clients", key: { name: 1 }, field: "hashed" })? * If the collection is empty, shardCollection creates the unique index on the shard key if such an index does not already exist * If the collection is not empty, you must create the index first before using shardCollection * both are true * 3
MongoDB does not support unique indexes across shards unless the unique index includes the full shard key as the first part of the index. If an index on the shard key is missing, a ? index that begins with the shard key should be used * compound * primary * hashed * 1
In MongoDB sharded collections require an index that includes the shard key, which can be: * an index on the shard key and a compound index with the shard key as the prefix * same but "or" * only the first is valid * 2
In MongoDB, for range-sharded collections, only the following can be unique: * an index on the shard key AND (a compound index with the shard key as a prefix OR the default _id index (uniqueness enforced per shard if _id is not the shard key or its prefix)) * same but "and" and "or" inverted * only the second part is valid * 1
What is the false sentence for MongoDB? * For unique compound indexes with the shard key as a prefix, the collection also needs a unique index directly on the shard key * Unique constraints are not allowed on hashed indexes * The choice of unique or non-unique index doesn't depend on identifiers identified during aggregate modeling * 3
? is a highly available, fault-tolerant NoSQL database with a peer-to-peer architecture, offering eventual consistency, consistent hashing for partitioning, and a leader-less replication model, but lacks support for ACID transactions and prioritizes availability and partition tolerance (AP) in the CAP theorem * Mongo * Cassandra * Redis * 2
"Where" is posed a column-family db with respect to opacity level? * more than k-v * in the between * less than mongo * 2
Columns can be organised into ?: sets of related data (columns) that are often accessed together * families * groups * keys * 1
In column-family databases, pairs of key-value data can be grouped into logical collections or namespaces, with each collection resembling a table; schema information can be provided during data insertion (DML) or beforehand (DDL), and while columns within a collection must belong to the same column-family, different rows may have varying sets of column ?, offering ? * scope, flexibility * names, flexibility * names, scalability * 2
In column-family databases, a key-value pair is used where the key serves as a unique identifier for data retrieval at the logical level, and at the physical level, the key determines data partitioning and storage location; the partition key, often a ? of the primary key, is required for direct retrieval, and primary key attributes may also be used for retrieval alongside the partition key, subject to certain restrictions * superset * strict subset * subset * 3
In Cassandra we have: * Tables aka Families (Table in RDBMS) * Rows aka Aggregates (Row in RDBMS) * both * 3
In Cassandra the partition key correspons by default of * the primary key * the first attribute of the primary key (otherwise I specify with double parenthesis) * both * 2
In Cassandra we have no primary key violation: if you insert a row with the same primary key of another row in the table, the first will be simply updated, so: * we can't specify UNIQUE values * INSERT becomes an UPDATE * nO CASCADE modifier * 2
In Cassandra what is the side effect of not being able to specify the foreign key? * e.g Table video can refer movies not included in table movie * I can Join on everything * both * 1
In ? marks data for removal from a table data is removed later through a process called ? * Mongo, transactional delete * Cassandra, compaction * Hadoop, compaction * 2
In column-family databases, ? are attributes that follow the partition key in the primary key definition, and rows with the same partition key value are locally sorted by these clustering columns, typically in ascending order * clustering columns * primary keys * sharding keys * 1
In Cassandra ? tells where I find the node, ? tell the order in the same node * partition key, clustering columns * clustering columns, partition key * both the same * 1
In Cassandra what are you doing saying that movies is a set<frozen<movie_t>>? * that the system will see movies as a set of movies * that the system will see movies a set of black box binary objects that you documented as being movies * that the system will treat values for movie_t as a blob but to select it you don't need to operate at the application level * 2
It is mandatory to use Frozen in Cassandra when you want to use... * an user defined type * more nested collection types * both of them * 3
In ? there's "value get(collection, key, family, column)" * MongoDB * Cassandra * RDF * 2
Column-family systems with SQL-like languages allow only partition key-based queries determined at compile time, lack support for joins and nested value access, but can use indexes for additional query execution * true * false because they also support other type of queries * false because they have nested value access * 1
CQL SELECT has strict WHERE clause restrictions, disallows joins, limits projection conditions, and some queries are non-executable, with solutions like query-based design, indexes, and forcing non-admitted query execution * true * false, it limits selection conditions * false, all queries are executable * 2
CQL SELECT restricts queries to a single table, disallowing joins due to high data communication costs across nodes, with solutions being ? or ? * query-based design * custom applications to perform joins * both * 3
CQL SELECT requires equality-based conditions on each partition key attribute in the WHERE clause, allows IN clause for partition keys, supports ordered clustering column conditions (IN ORDER), and mandates sequential storage of rows on identified nodes * this is mandated by the physical consequence on having all data with same partition key on the same node * this is mandated by the physical consequence on having, once taken the node, all data ordered with respect to clustering columns * both * 3
In Cassandra, if more than one clustering column has been defined, ? restrictions are allowed only on the last clustering column being restricted in the WHERE clause * range * query * selection * 1
In Cassadìndra an index can be created on any column to enable new queries, and * the index is global * the index is local at any node * you can't create indexes * 2
In Cassandra you can query sets/lists with ? and create index on maps with keys, values and ? (for both) * in, entries * contains, pairs * contains, entries * 3
Local persistence in nodes involves a three-step write process, logging to local disk, updating an in-memory cache, and flushing to disk as an SSTable when full, while read operations prioritize disk data * true * false, because they prioritize in-memory data * false, because they periodically flush SSTable * 2
Configurable read/write consistency allows setting a consistency level per query or operation by defining parameters w and r in the formula w + r > n (where n is the number of replicas), with levels specified using the command CONSISTENCY <level> * true * false, because it's w + n > r * false, because the command is EVENTUAL <level> * 1
Suitable use cases for ? include high-write applications like event logging, content management systems, and counter tracking for web analytics, while it is less suitable for systems needing ACID transactions or rapidly evolving prototypes where frequent query pattern changes are likely * MongoDB * Cassandra * NeoJS * 2
