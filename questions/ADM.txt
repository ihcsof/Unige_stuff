What is a difference between large-scale data frameworks (e.g Hadoop) and large-scale DBMS? * frameworks don't provide a logical level * framework focus on data representation and querying * frameworks are tailored to transactional processing * 1
Connect RDBMS (1) and LSDBMS (2) featues: application database, semi-structured schema, flat data, joins are an issue and normalization is no more a reference, declarative lang (SQL) * 2, 1, 1, 2, 1 * 2, 2, 1, 2, 1 * 2, 2, 1, 1, 1 * 2
In ?? DB we start from the ?? to model our data, and all the (any) app that will need that data will come later (with different views) * application, domain knowledge * 
application, relational schema * integration, domain knowledge * 3
An ?? is tailored to account for the design of a niche of apps, with data exchange between apps based on specific format (e.g JSON) and with the chance of putting ACL and integrity checks in the ?? * application DB, app code * application DB, DB code * integration DB, app code * 1
?? are inefficient for large volumes of data (if data are partitioned in 2 nodes, it'll be made 2x2=4 times), so in app DB we use query-based design * products * joins * CRUD operations * 2
?? is a term used to describe the problem that arises when two systems or components that are supposed to work together have different data models or structures that make communication difficult * Impedence mismatch * Inconsistencies * both * 1
Graph based systems are tailored to app where complexity of data is the most important point, while Aggregate oriented systems are designed to deal with common large scale issues * TRUE * FALSE, the opposite * completely FALSE * 1
?? architectures are often P2P, designed for transactional (read/write intensive) scenarios, with hash-based or range-based partitioning for efficient resource usage, leader-less replication, eventual consistency, high and tunable availability, high fault tolerance (often with no master, P2P ring), usually no ACID transactions, and following the AP or CP theorem in the CAP theorem. * Graph based * Aggregate-oriented * None * 2
The notion of aggregate (a data unit with a complex structure)...: * impact the logical level * impact the physical level * both * 3
A ?? exists only if a system that uses that level also exists, and it is a set of constructs that helps us in representing entities and associations corresponding to a general/reference domain * conceptual * logical * None * 2
An aggregate is the unit of interaction with the data store, so: * you have to partition them * you can partition them * you can't partition them * 3
In Application DB there's no such thing as ??, because the logical schema was built with respect to the needs of the few apps that will use it * External (Views) Level * Logical Level * SQL Middleware * 1
?? define how data is logically and physically grouped, impacting search efficiency, concurrency control, and consistency, with NoSQL databases typically supporting atomic manipulation of a single aggregate at a time to avoid inconsistent reads during multi-aggregate updates * Logical views * Aggregate properties * Graph views * 2
These aggregate-orieted logical data models are in what order? Key value, Document-oriented, Column family * increasing data size * increasing data complexity * decreasing data complexity * 2
In aggregate-orieted logical data models, at the physical level, the key is the ??: different aggregates associated with the same key are stored in the same node * partitioning value * JSON required fields * the (non necessarily unique) key of an entity * 1
Without considering a specific aggr.-oriented system: starting from a conceptual schema and a ?? we want to translate them in a meta-logical schema (using JSON ??) * workload, schemas * workload, tables * logical, tables * 1

